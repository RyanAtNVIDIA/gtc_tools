{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d981733f-5ca8-4d50-b3c5-27568794e1a5",
   "metadata": {},
   "source": [
    "# GTC Keynote Playlist Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73dd537-42c3-49f6-85c5-ff0f81a762f6",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c2300c2-080b-4acf-82f5-05ebd195dcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import gtc_spring23 as gtc\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513ffb87-c346-4f2f-9cbe-b1ce5fd915fa",
   "metadata": {},
   "source": [
    "## Notebook variables and Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60d7f96b-c426-41b4-95e5-14cbd1413eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'msmarco-distilbert-base-v4'\n",
    "query_string = 'USPS'\n",
    "playlist_count = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4573d76-a615-4b6a-8d95-7122f6e305e8",
   "metadata": {},
   "source": [
    "## Embed keynote sections, query term, and perform semantic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43cefcaa-e92a-4ec5-b07f-44465fa87553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: 'msmarco-distilbert-base-v4'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e5c8d0a93aa48f9b1f435b6e6abe30e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)98e3c/.gitattributes:   0%|          | 0.00/690 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97c439696d2146c8a397edfc7ba64e44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5f5428957864647b432b361b7679279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ea4b998e3c/README.md:   0%|          | 0.00/3.71k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b5971b6eb25478eaa649d985ddc5b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)4b998e3c/config.json:   0%|          | 0.00/545 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddf4ae76b5bf4cb18d6c0da4dd60bbb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd28975fbea5462ca1322d5a0a202012",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/265M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11ff910c799d4b4bb9b6cd7cc2e3cbe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4f87d8099f9452ab6bc239aef988900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f32d066af6d459db809cc14d6997e38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)98e3c/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20c50331e97048109a9944964700ba05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/319 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aed54c314f2d4cc48035ff8b94cfbf17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ea4b998e3c/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00c731e81fdd421297bee895fadb74fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)b998e3c/modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding GTC Sections.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbb19d989e2a426da641e7e180f7e9fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding query.\n",
      "CPU times: user 3.49 s, sys: 1.87 s, total: 5.35 s\n",
      "Wall time: 30.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Loading model: '{}'\".format(model_name))\n",
    "model = SentenceTransformer(model_name,cache_folder='./models/')\n",
    "\n",
    "print(\"Embedding GTC Sections.\")\n",
    "source_embeddings = model.encode(gtc.section_text,convert_to_tensor=True,show_progress_bar=True)\n",
    "\n",
    "print(\"Embedding query.\")\n",
    "query_embedding = model.encode(query_string,convert_to_tensor=True)\n",
    "\n",
    "# Using the util function to run semantic search, default to cosine\n",
    "topk_results = pd.DataFrame(util.semantic_search(query_embedding, source_embeddings, top_k=playlist_count)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6681e1-40b4-4a3d-a3fa-b5fb7ac78d21",
   "metadata": {},
   "source": [
    "## Display the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65384d7c-70bc-4fd7-b26a-34c9ed6f6e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following top 5 sections are ranked in order of relevance to the query term: 'USPS' using msmarco-distilbert-base-v4 as an embedding model\n",
      "\n",
      "Section: L4 Announcement\n",
      "Chapter: 6) NVIDIA Inference Platform\n",
      "Section URL: https://youtu.be/DiGB5uAYKAg?t=3080\n",
      "Section Summary (bart-large-cnn): Snapchat is a leading user of NVIDIA AI for computer vision and recommender systems. Snap will use L4 for AV1 video processing, generative AI, and augmented reality. One 8-GPU L4 server will replace over a hundred dual-socket CPU servers for processing AI Video.\n",
      "Score: 0.10323788970708847\n",
      "\n",
      "Section: Route Optimization\n",
      "Chapter: 2) Acceleration Libraries\n",
      "Section URL: https://youtu.be/DiGB5uAYKAg?t=938\n",
      "Section Summary (bart-large-cnn): AT&T is tapping into NVIDIA accelerated computing and AI for sustainability, cost savings, and new services. cuOpt can also optimize logistic services. 400 billion parcels are delivered to 377 billion stops each year. Deloitte, Capgemini, Softserve, Accenture, and Quantiphi are using NVIDIA cuOpt to help customers optimize operations.\n",
      "Score: 0.09546720236539841\n",
      "\n",
      "Section: L4 GCP Announcement\n",
      "Chapter: 6) NVIDIA Inference Platform\n",
      "Section URL: https://youtu.be/DiGB5uAYKAg?t=3130\n",
      "Section Summary (bart-large-cnn): Google announced today NVIDIA L4 on GCP. NVIDIA and Google Cloud are working to deploy major workloads on L4. First, we’re accelerating inference for generative AI models for cloud services like Wombo and Descript. Second, we're integrating Triton Inference Server with Google Kubernetes Engine and VertexAI.\n",
      "Score: 0.05957096070051193\n",
      "\n",
      "Section: ChatGPT\n",
      "Chapter: 5) DGX Cloud & Generative AI\n",
      "Section URL: https://youtu.be/DiGB5uAYKAg?t=2168\n",
      "Section Summary (bart-large-cnn): ChatGPT, Stable Diffusion, DALL-E, and Midjourney have awakened the world to Generative AI. These applications’ ease-of-use and impressive capabilities attracted over a hundred million users in just a few months ChatGPT is the fastest-growing application in history. No training is necessary. Just ask these models to do something.\n",
      "Score: 0.010181012563407421\n",
      "\n",
      "Section: Data Center Introduction\n",
      "Chapter: 3) Data Center Hardware\n",
      "Section URL: https://youtu.be/DiGB5uAYKAg?t=1603\n",
      "Section Summary (bart-large-cnn): Cloud computing has grown 20% annually into a massive $1T industry. As Moore’s Law ends, increasing CPU performance comes with increased power. The mandate to decrease carbon emissions is fundamentally at odds with the need to increase data centers. Acceleration will reclaim power.\n",
      "Score: 0.005710551515221596\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"The following top {playlist_count} sections are ranked in order of relevance to the query term: '{query_string}' using {model_name} as an embedding model\\n\")\n",
    "\n",
    "for i in range(playlist_count):\n",
    "    #idx = topk_results_ids[i]\n",
    "    idx = topk_results['corpus_id'][i]\n",
    "    print(f\"Section: {gtc.section_name[idx]}\")\n",
    "    print(f\"Chapter: {gtc.chapter_name[idx]}\")\n",
    "    print(f\"Section URL: {gtc.section_url[idx]}\")\n",
    "    print(f\"Section Summary (bart-large-cnn): {gtc.section_summary[idx]}\")\n",
    "    print(f\"Score: {topk_results.score[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa2b45c-378c-470b-a1a8-57968fcecfbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
